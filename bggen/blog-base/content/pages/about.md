Title: About
save_as: index.html
Template: about
remove_footnote_section: true
my_title: Siegel Postdoctoral Fellow
my_affiliation: University of Washington

I have broad interests in generative AI, NLP, and multimodal systems. In particular, I'm interested in:

1. Rigorous evaluation of **difficult-to-measure capabilities** in language models and generative image systems. ([COLM 2024](https://arxiv.org/abs/2407.16711)[^1], [NeurIPS 2024 Spotlight](https://arxiv.org/abs/2404.04251)[^2])
2. Building **multilingual and culturally competent** generative AI systems, addressing *performance disparities, bias, and unique knowledge possession*. ([ACL 2023](https://aclanthology.org/2023.acl-long.266/)[^3], [FAccT 2023 Oral](https://www.youtube.com/watch?v=tBYJFLaM71U), [NAACL 2024](https://aclanthology.org/2024.naacl-short.48/))
3. Advancing multimodal (primarily vision & language) generative AI systems, in particular with respect to deep semantic understanding. ([EMNLP 2024](https://aclanthology.org/2024.findings-emnlp.312/)[^4], [Tech Crunch coverage](https://techcrunch.com/2024/06/29/geminis-data-analyzing-abilities-arent-as-good-as-google-claims/))

[^1]: In our work "Benchmarks as Microscopes: A call for Model Metrology" we lay out an agenda for building a science of evaluation.
[^2]: ![example image](https://t2iscorescore.github.io/static/images/ts2teaser.svg)<br>We introduced [`T2IScoreScore`](https://t2iscorescore.github.io), a meta-evaluation of text-to-image faithfulness metrics that uses "semantic error graphs" to evaluate how well metrics can rank closely related images with objective error counts.
[^3]: My `CoCo-CroLa` evaluation of "multilingual conceptual coverage" in text-to-image models was the first assessment of the multilingual capabilities of T2I systems. It is produced through a *fully automated benchmark generation pipeline.*
[^4]: We introduced *long-context visual extractive reasoning,* a more ecologically valid measure of long-context understanding in vision-language models than prior "visual needle in a haystack" tests, and demonstrated that long-context VLMs are much worse at the task than previously believed.

I have had the wonderful opportunity to mentor [over a dozen students in research](./mentorship/) over the course of my PhD. <!--If you are interested in knowing even more about me, here's [some fun facts](./lore/)-->